{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtYNPhQaoCT_"
   },
   "source": [
    "# Generative Models with Catalyst\n",
    "\n",
    "Today we are going to learn about generative models.\n",
    "\n",
    "We'll work with handwritten numbers, but we will generate with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:05.950335Z",
     "start_time": "2022-01-13T16:50:05.195427Z"
    },
    "id": "db7ZGBuvoIKw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catalyst==21.06 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (21.6)\n",
      "Requirement already satisfied: tensorboardX<2.3.0>=2.1.0 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from catalyst==21.06) (2.2)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from catalyst==21.06) (1.20.2)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from catalyst==21.06) (4.59.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from catalyst==21.06) (1.8.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from catalyst==21.06) (6.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from tensorboardX<2.3.0>=2.1.0->catalyst==21.06) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages (from torch>=1.3.0->catalyst==21.06) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install catalyst==21.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:16.491621Z",
     "start_time": "2022-01-13T16:50:16.486255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.06'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catalyst\n",
    "\n",
    "\n",
    "catalyst.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:17.537816Z",
     "start_time": "2022-01-13T16:50:17.422306Z"
    },
    "id": "h2qZ-FsboCT_"
   },
   "outputs": [],
   "source": [
    "from catalyst.utils import get_device, set_global_seed\n",
    "\n",
    "\n",
    "set_global_seed(42)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFBzcQWwoCT_"
   },
   "source": [
    "We'll work with `MNIST` dataset. Download it, show examples of the writting and prepare the dataset to be loaded into models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:18.633515Z",
     "start_time": "2022-01-13T16:50:18.607271Z"
    },
    "id": "wL8RED6koCUA"
   },
   "outputs": [],
   "source": [
    "from catalyst.contrib.datasets import mnist\n",
    "\n",
    "\n",
    "train = mnist.MNIST(\".\", train=True, download=True)\n",
    "valid = mnist.MNIST(\".\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:19.222123Z",
     "start_time": "2022-01-13T16:50:19.214425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:20.870662Z",
     "start_time": "2022-01-13T16:50:20.172019Z"
    },
    "id": "t_AYY5SzoCUA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAJACAYAAAB/pjm4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAABadUlEQVR4nO3dd5xU1f3/8fdh6VVARASkLmCNKPYWO3YTo5EYg9F8SewaNWqSX2K6icbYY1AJRg32KDEmRhGNsSCoWBApUhSkiAoiUrac3x9skv3csztnd2Z25s7u6/l4+HDfd+7ce9b9OBxmPnuO894LAAAA9WtV7AEAAACkHRMmAACACCZMAAAAEUyYAAAAIpgwAQAARDBhAgAAiMhpwuScG+2cm+Ocm++cuzxfg0LLQh0hV9QQ8oE6QiYu23WYnHNlkuZKOkzSEknTJY3x3r9d33Pauna+vTpldT+k1wat0ya/0WXz3MbWETXUfK3VJ6u8970a+zxei/AfhXwtkqij5qq+OmqdwzX3kDTfe79Akpxz90o6XlK9xdVenbSnOySHWyKNpvkpuTy9UXVEDTVfT/kHF2f5VF6LIKmwr0USddRc1VdHuXwk11fS+7XykppjhnNunHNuhnNuRoU25nA7NFPROqKGEMFrEfKBOkJGTd707b0f770f5b0f1Ubtmvp2aIaoIeQDdYR8oI5arlwmTEsl9a+V+9UcAxqDOkKuqCHkA3WEjHKZME2XVO6cG+ScayvpFEmT8zMstCDUEXJFDSEfqCNklHXTt/e+0jl3rqQnJJVJmuC9n5W3kaFFoI6QK2oI+UAdISaX35KT9/5xSY/naSxooagj5IoaQj5QR8iElb4BAAAimDABAABEMGECAACIYMIEAAAQwYQJAAAgggkTAABABBMmAACACCZMAAAAETktXAkAQEP4fXcJjrX++UqT31ncx+Ty019pyiGhltZ9tzF5yc3dTJ6x+93Bc9q4MpMrfJXJO9x5rsnbPF8ZXKPD0nUmV898Oz7YIuEdJgAAgAgmTAAAABFMmAAAACLoYcqSa23/05X12rLR15hzyUCTqzpWmzxgiP18X5I6nu1MXn5tW5NfHXWfyauq7OfDkrTnAxebPPS7L0XHCqD5KOve3WTXvVs9ZzZc9XL7etWq+xYmL/puRfCcp4bcb/KXb7sk53EgOx8eOsDkF0ddb3KFj18j2cM08xv2GvpG+Jzvr9jH5LfP38Vk9/zM+I0LhHeYAAAAIpgwAQAARDBhAgAAiGiRPUxl25Wb7Nu1MfmDA7cInrN+L9sL1KObzc99wfYO5cPfP+8SHPv1TaNNnrbTn01eWLHe5KtWHBZcY5vnGvBhNIBmodXOI4Jjw/443+Tr+kw1ucrbfsqGOOndI0y+uN9jJm9T9nnwnBN+eKnJW/z5xUbfF9kp27KnyXudN6Mo4/hl7xdsvnmjya9+ZajJVfMXNvmY6sM7TAAAABFMmAAAACKYMAEAAEQwYQIAAIhoEU3fVV/c1eRrJ95s8rA2dvHHYkku+vWjG08Pzmm9zjZs7/2A3dywy1K7uWG7VbYJXJI6zpiW5QjRHCQXXXVtM9e/rwg3zPQVm/I6JmSv9da9TV4yZojJU757dfCc7q06mFzh7evK2UsOMPnVlX2Da7y8670mPzDkCZPfrbSvPV/9sW3wlqTuf6LJu1iq135m8hNPjDL5qrHPR6+xrMr+jB9eu6PJR3SyG+kOaB2fcnx/S7vh8v2PrTB50gi7SXAh8Q4TAABABBMmAACACCZMAAAAES2ih6ndnA9MfmVDf5OHtbGfkebDxcv2Co4t+Mxu0DtxyIMmr6m2fQS9b7ALemWDJSqbF5fot2vVtbPJ8y8dbnLFFrYvTpJ222GByfcN/mfGew6d/J3g2LCzXs74HBTO/HMGm/z2GTclzuigpD1ePcXk9nf1MLnz/XZD7jVX20UOJUm2NTToWTr1SruRbo+J9CulybKzdjP5tbHXNfoah/7Z9qUNutz+jB/559dMfnx7u9lyQwxum9yEnh4mAACA1GLCBAAAEMGECQAAIKJF9DBVLltu8o2/PsnkX4y2G+mWvWH7QiTp9bNvzHiPn6/a2eT5h3YMzqlavczkr+19tsmLzrfnD9LrGe+J0ubatTN50/52DZOFY1zwnGEDbS3/dcTkxBlPRe9b5uzfk6oijW4Hj3w7OLYkehc0lZXn7mPyk2N/kzjDvvbs/f1zgmv0nvGxydVzXzV5zh12TZ67D7Jr10kN6Fn6Iz1LabHsu/sEx+4+/9rEkca/f5LsWUqqHJ9YI+y3FcE5/craZLzGwNZ2vaj3fxh+L/1/nnu/b0PwDhMAAEAEEyYAAIAIJkwAAAAR0R4m59wEScdIWum937HmWA9J90kaKGmRpJO995803TDzK/nZeq+/2jVGqj6yn+9L0g47nmHyrAMmmDx5/IEmb7U6/pmqe9H2KA1qxh/5N7c6Sq6HVNbfrg2ycYBd10aSFp5hm4X697bf6pQdbsvT6PLrxcd2Do71V2F6BmprbjXUEK379wuOffvsR03uW2Z7loY+atfNGn6v7U+SpKqNG02uONSuyTN/9HiTL19hH5ekZ2+wa82VyjpLLaGOWnXqZA8cEH4rQ1tnfr9kSZXtNzr1J5cE5/RQ5p95pwftvqXfdN8Nznnyd5n7g7dsZV9r+x/0XnBOq+u7mFy9dm3Ga2arIe8wTZQ0OnHscklTvPflkqbUZCCTiaKOkJuJooaQu4mijpCF6ITJe/8vScm3XI6XdGfN13dKOiG/w0JzQx0hV9QQ8oE6Qray7WHq7b3/z+/IL5fUO9PJQD2oI+SKGkI+UEeIyrnp23vvlWHLMufcOOfcDOfcjAptrO80tHCZ6ogaQkPwWoR8oI5Qn2wXrlzhnOvjvV/mnOsjKbk73n9578dLGi9JXV2PVO4FW7Xqo+g5FZ+2zfj4Dqfaxf0+/H1ZeFJ1uBFqC9egOkpDDS2/yC6W1uEwO9Tnv9D4TSVjVlZ9Hhz79sKvmLzwr4ODc2pbt9OG4NjsQ/9gcmvZWj3vA/u9bntVuNFuiv5HblavRUnLbu4UHPu/bu+bfOzcY0wefpH9ZRK/MfxD/d0/72LyX/exjbcrq6pNfvlHuwfX6P5YaTR5N1BJ11FZT/tLJrOvGWTyrFG/j15j6oauJl/5i2+anI+FSLssXBc/KeIvwx8Ojo383gUmD/x/TVOb2b7DNFnS2Jqvx0p6NMO5QH2oI+SKGkI+UEeIik6YnHOTJL0oabhzbolz7kxJV0k6zDk3T9KhNRmoF3WEXFFDyAfqCNmKfiTnvR9Tz0OH5HksaMaoI+SKGkI+UEfIVovYfDcftrtsrsnf3Mn+v/XHAVNMPvCkcMPLLve9lP+BISq5yOSc8TuZ3HkLu4loXS7dzvYondql3haHen1Ube9z9qLjTZ7/wDA7rqVhz1unh+xCcNtoeXBObe9es1dwbE31JpN7tupg8lNPjTR5UHXYw4SmkVyo8ptD4q8Zqz63fU7dN35g8geXhpuVTt//GpPbJDZkPux7doHBro/x2pVms6+2vYyzDrul0df41fyjTG6KzZPLlq4Kju3/2tdNfm7k3Xm/b76wNQoAAEAEEyYAAIAIJkwAAAAR9DA1UNXqNSZ/dNZ2Jr832fanXP7zPwXXuOLkL5nsX+tmcv9fJD4z9qlY4qPkrTzTbhx62Z6TTU6ua5ONH3/4BZMfv3W/4JwOH9m1bTo/YPuReiv8fL+xqvfbxeTRB74WnJPsWTp6zrEmD3g8sXYT64cVTNUy25P27MflwTlnb7HQ5JMG2M11x//6cJP/ecpvgmt0bWU37D3gorPt4/fTs1RKJn3xD/GTUqByWdhzWfFMYi25kcEpqcE7TAAAABFMmAAAACKYMAEAAETQw5Sl6tdnm3zKTy41+Z4f23VOJGnmXom+psQSOTt0Otfk8tuWKalywaKGDxKSpLJj7F6ByZ6l7f99usld/xHu3xXT63m7LlOvucXZZ2vhl9qb/KfeU4JzylxnkzdcvY3J7Z6bnv+BoUF8ZaXJa/cP+9rGvnCwyXcPfMbkS09L7hvWWUmDH/62yeX0LJWUTU8OMHm3dq8kzrD7Q/7x0/7BNR76YFeTO41ekJexNZZ3NrdxdezDGuPip+QD7zABAABEMGECAACIYMIEAAAQwYQJAAAggqbvPOkxwTb5njsn3Hy361VLTJ40+AmTZ33jJpNH9P9WcI3hP7Fz3Kp5xWnUKyU9jnvX5H3H2EX6Br++2uTqt95o9D2KtbSj39sumHn8F+1GuVuV2QUKJWnkL+33v/VUu/ChXV4TafP87KEmVw14utHXOGVf+3o16bY9Td7uUrvZeHLhXhTOpiNGBceO6jPV5Aqf+RXo5vEnBMe2/t0LOY0rX1xifebY9/LHT4cEx3pPL8wrMO8wAQAARDBhAgAAiGDCBAAAEEEPUxNxz88Mjn3+la1M3v2r55k87bLrTX7noNuDa5w60G6suSbc4xVJic1ju91jF+kr5Z6dxRfaBoA7e/3L5J+usr0pktRn0jsmV23YEJyDdNg0evfg2N0H2Y1WT5x/pMkLH7E9Hp/tajcGl6T797PX+OXRtm/vhGFHmLz+QHqYiuWDA9oEx87ZYnYdZ6Zf2bCw/+i4057L+Jz5lfYV+qHzDw/O6fDUy8GxpsA7TAAAABFMmAAAACKYMAEAAETQw1RAVSvsBq29b7B5w/fsxpsdXdvgGrcNfMzkY750oX3OX6blMEKk3btX723yM3tfbXJy3aXHbj4guMZW617L/8CQF612HGHyT265LTinV5ntSdpwcS+Tt54RX1/nlF9fYPK8xIa9F/Z70uRfaefoNZEfyXWXHv/61XWcFf7ZUNvu075p8rZ/mBmcU4jezWTP0umPPRWcc0zHDzNeY3W13VC8zVPJjYYLh3eYAAAAIpgwAQAARDBhAgAAiKCHqYlU77dLcOzdk+xnsTvussjkunqWkm78eKR9zqMzGj02lIaNR4dr8FxxzF9M7pPoWRpxl93DcOjdrwfXqGbdpdRo1aWLyQv+n30N2Ldd2Gmy628uNbkhPUtJvh81kFa+tTO5T1n8z4WkTRvt2k3Vn3+e05jq03rgtia/f2I/k5NrLMX6leryf9O/YfJANX6vz3zhHSYAAIAIJkwAAAARTJgAAAAimDABAABE0PSdJTdqR5Pnnm8b827b987gOQe039Soe2z0FcGxlz4eZA9UL2vUNVE63IUrg2Ond/0g43O2ed5uNNxUzZ7Ijzk/38HkefvdYvKBb34leE7fe+aYXJV4PLlYYNvbPguuMWvoeJM32j2cdc4ddmHLfmp8YzlK26pxdpHctQevC84Z1Otjk18afl3O993luf8zeej59jUvWe+FxDtMAAAAEUyYAAAAIpgwAQAARER7mJxz/SX9SVJvSV7SeO/99c65HpLukzRQ0iJJJ3vvP2m6oRZO60EDgmPvfnMbk6/86r0mn9h5Vc73/f4Ku+nis9fvFZzT/c4Xc75PMbTEOmqspQ/bfpYnh/8hOOe2NcNNvveSo0zu+MxbJhdig81CaQ411LpfX5MfPu56k29bM9jkrl9fE1zDdbWLXb57RbnJ1x73J5OP7hj2MN2auM8tdx1rcr9fNd+epeZQRzEP7G1fO55/e2ijr7F7hxtM3rGND85p48pMrghPMTb6yuDYXi98x+SgZ+nDxi922VQa8g5TpaSLvffbS9pL0jnOue0lXS5pive+XNKUmgzUhzpCrqgh5AN1hKxEJ0ze+2Xe+1drvl4rabakvpKOl/SfXwW7U9IJTTRGNAPUEXJFDSEfqCNkq1HLCjjnBkoaKWmapN7e+//8TvtybX57s67njJM0TpLaq2Ndp6CFaWwdUUNI4rUI+UAdoTEaPGFyznWW9JCkC733nzr3vw0CvffeOVfnp5fe+/GSxktSV9cj8glnYSQ3DFyzWx+Tv/rTfwTP+c4WD+d834uX2Z6kF2+xPUs9Jr5scvfq0uxXyiSbOkpjDeVDxeH25//07rafpWer8MX4n6u2N7nDM7NMbgnrLpXKa5Fr1y449vFtdgPundraTVIXVdqepSVjbc+aJB1xqn1dmNw782vT7q+MCY71ucBuvttvYfPtWapPWuuo3Yf2Z3PjJzsE55zXfVZwrLZhbVwiv5v7wLJwybIDTP7HrPB7KT/9FZOLuc5STIN+S84510abC+se7/1//u9c4ZzrU/N4H0nhKntALdQRckUNIR+oI2QjOmFym6fdd0ia7b2/ttZDkyWNrfl6rKRH8z88NBfUEXJFDSEfqCNkqyEfye0r6TRJbzrnZtYc+76kqyTd75w7U9JiSSc3yQjRXFBHyBU1hHygjpCV6ITJe/9vSa6ehw/J73By17rP1sGxjyd0MvmsQc+aPKbLipzve+7S/Ux+9fe7BOds+aBdI6fH2ubXo1SfUqujQnjvMNu/0rNVh+hzPvydXT+n4+fT8jqmNCu1GmrVuVNw7N87P5DxOcd2/NTm794Uvc9da+1r3m9vt/vP9b3O9kZKUmVluB5OS5H6Onr5TROfuPjA4JQJ+x9q8uPfuNrkPmV2b9NCOX3RkSavPWcrk8tft/1KpYaVvgEAACKYMAEAAEQwYQIAAIhgwgQAABDRqJW+02DTEXaxv00XfWzy94c+Hjzn8A7rcr7viqr1Jh8w+WKTR/zwHZN7rA4bupvTRqhovMpDdjP54ZN+lzjDNmoOv/fs4BpDH3/N5GazimczVPVxuG/rXv/vHJO/dOHTJu/XeY7Jpz/+7eAanRfaDU/73vq6yduss4tQUiOlrc0/ZwTHBv7T5q8uvtTkf11pF8HNhz1vuDA41vPNCpM7LrYLr1a/PTvv4ygm3mECAACIYMIEAAAQwYQJAAAgouR6mBadYOd4c3fKvBBcXW5ePcTk65893GRXFa5pNuLnC00uX2EXDEzzhoFIh/cPsT1KO7TJvLhcq01hHfqNG/M6JjQhH3YP9ZhgexufnWAXK31Wu5hcrvjCpPRGoufttq6+dPseeb/HNopv0Nzc/xzkHSYAAIAIJkwAAAARTJgAAAAiSq6HadhZdiPJY87arZ4zG3FNhZtTJjX3z2aRPn1eoOoAIC14hwkAACCCCRMAAEAEEyYAAICIkuthAkrVoB8m+u9+uk/G89tveqUphwMAaATeYQIAAIhgwgQAABDBhAkAACCCCRMAAEAETd9AoVTbhSirN7AwJQCUCt5hAgAAiGDCBAAAEMGECQAAIMJ57wt3M+c+lLRY0paSVhXsxtljnA0zwHvfqxA3qlVDUvG/74ZinA1TjDoq9vfcUIyzYQpWQxJ11ISKPc4666igE6b/3tS5Gd77UQW/cSMxznQrle+bcaZXqXzPjDPdSuX7Zpy54SM5AACACCZMAAAAEcWaMI0v0n0bi3GmW6l834wzvUrle2ac6VYq3zfjzEFRepgAAABKCR/JAQAARDBhAgAAiCjohMk5N9o5N8c5N985d3kh7x3jnJvgnFvpnHur1rEezrknnXPzav7dvZhjrBlTf+fcVOfc2865Wc65C9I61qZCHeU8xhZfQ1J666gUaqhmTC2+jtJaQ1Jp1FGp1VDBJkzOuTJJN0s6UtL2ksY457Yv1P0bYKKk0Yljl0ua4r0vlzSlJhdbpaSLvffbS9pL0jk1/x3TONa8o47yokXXkJT6Opqo9NeQ1MLrKOU1JJVGHZVWDXnvC/KPpL0lPVErXyHpikLdv4FjHCjprVp5jqQ+NV/3kTSn2GOsY8yPSjqsFMaap++XOsr/eFtUDdV8f6muo1KroZpxtag6SnsN1YyppOoo7TVUyI/k+kp6v1ZeUnMszXp775fVfL1cUu9iDibJOTdQ0khJ05TyseYRdZRHLbSGpNKro1T/bFpoHZVaDUkp/tmUQg3R9N1AfvNUNzVrMDjnOkt6SNKF3vtPaz+WtrHif9L0s6GGSlPafjbUUWlK08+mVGqokBOmpZL618r9ao6l2QrnXB9Jqvn3yiKPR5LknGujzcV1j/f+4ZrDqRxrE6CO8qCF15BUenWUyp9NC6+jUqshKYU/m1KqoUJOmKZLKnfODXLOtZV0iqTJBbx/NiZLGlvz9Vht/ny1qJxzTtIdkmZ776+t9VDqxtpEqKMcUUOSSq+OUvezoY5KroaklP1sSq6GCtzQdZSkuZLelfSDYjdwJcY2SdIySRXa/Fn0mZJ6anOH/jxJT0nqkYJx7qfNb0++IWlmzT9HpXGs1FE664gaSncdlUINUUfprqFSqaNSqyG2RgEAAIig6RsAACCCCRMAAEAEEyYAAIAIJkwAAAARTJgAAAAimDABAABE5DRhcs6Nds7Ncc7Nd86lYzdhlBzqCLmihpAP1BEyyXodJudcmTYv2HWYNi+KNV3SGO/92/U9p61r59urU1b3Q3pt0Dpt8htdNs9tbB1RQ83XWn2yynvfq7HP47UI/1HI1yKJOmqu6quj1jlccw9J8733CyTJOXevpOMl1Vtc7dVJe7pDcrgl0mian5LL0xtVR9RQ8/WUf3Bxlk/ltQiSCvtaJFFHzVV9dZTLR3J9Jb1fKy+pOWY458Y552Y452ZUaGMOt0MzFa0jaggRvBYhH6gjZNTkTd/e+/He+1He+1Ft1K6pb4dmiBpCPlBHyAfqqOXKZcK0VFL/WrlfzTGgMagj5IoaQj5QR8golwnTdEnlzrlBzrm2kk6RNDk/w0ILQh0hV9QQ8oE6QkZZN3177yudc+dKekJSmaQJ3vtZeRsZWgTqCLmihpAP1BFicvktOXnvH5f0eJ7GghaKOkKuqCHkA3WETFjpGwAAIIIJEwAAQAQTJgAAgAgmTAAAABFMmAAAACKYMAEAAEQwYQIAAIhgwgQAABCR08KVANBS+X13Mfnj7TqY3PP2Fws4GgBNjXeYAAAAIpgwAQAARDBhAgAAiKCHqQ6uXbvgWKshA0x+59s9TL7qyEkmn9x5TfQ+w54da3KXZzqavOUf6IEA0ursiQ+afGD7lSZ/aekFwXPa/X16k44JQNPhHSYAAIAIJkwAAAARTJgAAAAiWmYPU6syE8u6djb5/XE7BE959YIbTV5Rtd7kjd6e/25FeNt2zuZZB0ww+dadB5t87S5HBNfo+aode8/b6HMCCuGDS/Yx+fAOL5vczrU32bdO/A+fIq61femfM34Xk1utsY8Pveilph4SUu7TMXsFxz48doPJF+0yxeRx3RaZ/J33Dwyusej7w01u/fQrWY6w6fEOEwAAQAQTJgAAgAgmTAAAABFMmAAAACJKv+nb2cbK1tv0CU5Z+uWBJq/ZdaPJX975NXvJ4xYF19i5w3kmD3zoY5Or33onNlK12nGEyV954BmTv7PFApuP+31wjR22OMPknrdFb4tmrPWA/iav3rOvycuO2RQ856xdnzW5V+u1Jv/k6RNMHna2bW5uqTb2sL/Z0c6V7suna9vW5PlHjDf5mQ1tTB635TeCaww/f5HJVZ98kp/BoSha9+9nctndlSb/a+jNwXOqVW1yq8R7MMnHb+1vX3sk6eXb/2XyTwfvGh9skfAOEwAAQAQTJgAAgAgmTAAAABGl+yF8jbIttjD5phfuD86pTuRTfnKpya/eaz8zbbfqzeAaA6+xm+lWr1vX8EH+5zmJPqdbr/6Syd/42U0mv1dpF8dE87LxyN1NXtvf/u/4yT5h/9E+w941+Zie/zb5S53tBrB1ifUZ7H7U9SZfOuzrwTWq5r4bHGvuKrpXFXsIBfPF9nbl3bkH3xGcc9ju40xu888ZTTomZK9si27BsQ9Osws0v3K5/fOnWrZnr5XChViHP3SuyV3n2YWVp19uF3yu6xp7tPPBsbTiHSYAAIAIJkwAAAARTJgAAAAiSr6HKbn2x6EPXxKc887Jdv2IFxK9Qme+d5DJ766xa9lI0mf/2NrkvpPm23GsiPeOJG3cIvPmnEfec2lwrGKLltNHUSx1fd7vunXN+JwVh9s1TDYetSY459Yv3G1yeZvnTe7Wyq6Nk+w1ksJ+o6YwtI19WVh54FbBOT1bYA/TwuPtWkVVpdN6EfVJte2X7N6qQ5FGgqaQ7FeSpGmX217F6khvY7JfSZJG/HC2PdDP/jk57tQvmjy+/zPBNYY/eI7J5UrvRs+8wwQAABDBhAkAACCCCRMAAEBEtIfJOTdB0jGSVnrvd6w51kPSfZIGSlok6WTvfSo2Ehr2gzeCY7svtPvAtTl8lckXlz9p8onb2scl6Y3htnfo9LYXmtx3Si+T3dz3gmusPXx7k/903u8SZ9gfx+AHPg2u4V+bFRwrBWmuo+R6SMddPSU455zuczJeI7a2Ud3axk9J+OWqXUye9tFAk1dN2jZ6jRevvCnj4/Mr7B5SWz0b9ucVo5MuzTVUaqo//9zkve672OQ5Y26JXuO9w+3r1ZB/5j6uQmgJdbTgN3ub/M6p4f/zyZ6lH68cafLrx9p9KsuXTAuuEbwOvG3/zFp5ku3tHD3Mrt0lSSOmv535minSkHeYJkoanTh2uaQp3vtySVNqMpDJRFFHyM1EUUPI3URRR8hCdMLkvf+XpI8Th4+XdGfN13dKOiG/w0JzQx0hV9QQ8oE6QrayXVagt/d+Wc3XyyX1ru9E59w4SeMkqb06Znk7NFMNqiNqCBnwWoR8oI4QlXPTt/feS6p3RRLv/Xjv/Sjv/ag2apfr7dBMZaojaggNwWsR8oE6Qn2yfYdphXOuj/d+mXOuj6TGr9rYRJLNjJLU+4YX7IEbbPxTT9vs9tOzRgTX+N7XHzT5853tQm9/veBPJp+26LDgGus+s/+Z2jnb3rbXq6eZ3Pu9ZUpKc0NcFlJRR6032P+qJ3cNf3FAeXhh/LBqo8kHTD3f5I6z25vc95nPgmuUvbPYZL96qck9ZfO8G/ds9Dg/qraLFqZ8o92C1VD5n84y+Z3Tbq7nzM3GXfNQcOzu948wuXrm28E5heBa25f+YbuFv6QSs/9+9hdQPshpREWXiteifDnpMLsobnIjXUm6efUQk5NN3pVL7GtJQ3x0pm02v+Kye0w+rlPYRz/8obNNLj8/bC5Pi2zfYZosaWzN12MlPZqf4aCFoY6QK2oI+UAdISo6YXLOTZL0oqThzrklzrkzJV0l6TDn3DxJh9ZkoF7UEXJFDSEfqCNkK/qRnPd+TD0PHZLnsaAZo46QK2oI+UAdIVslv/luPlR9ZH/DtP/PXwjOuf+2XUwuu7B9cE5tdw18MuPjkjR1vd3ktduNdoPXqo/mRq+B3JVNfdXkr5333eCcE37xlMm3/N32orRdbTdSHnj/8uAaVfMWmFyuV4NzYmI9bMmNg688LOyjaePKTK5ItDd854+2p6C/wv8fWqLyq+3ipbNO2WTyDm3sQqSndP4wuEbFvbaO7h1jex2bYmHasq7hxtGrJtlfAntx2H2Nvu61fZ8w+divXGRypwfT24vS3Kz7x2CTf7LVAyb/7fNwQ/Enj7Ab8sZ6lioP3i049tEOtrfzlcvtApnJ3qlWCjec//MxdpHUH58f3ict2BoFAAAgggkTAABABBMmAACACHqYGqhqhV2Wo+uCIfWc2XAHddhg8q0/tGvsrH++U/Cc6nXrcr4vMuvw6MvBsScetX0gQ/RixmsUar2sVp1sjXwyaUuTv9olXMurwtu/J41ddKjJ2/7mFZPrXcGvhUn2Op54n+3ZeefrmddlkqTTutjetl4P2B6zc5/8hsnD7wjXlfMz3orep7bZ1wwPjs3f5Q+NukZdurayfZwf7Wh74zrZpevQhKbuZHuWkpt/3750/+A5i08dkDhi8+CjbM/lY0PHB9dI3ie5oW+4CXn4Hs037zzP5G1T3DPJO0wAAAARTJgAAAAimDABAABE0MNUl712Dg5VdbD/qT4aVWnyzi+cbvLu/Ww/Ul1+vM3jJt835B8mX/DMvsFznv673atnwI8y99KgeXMD+pr8zM731HPm/7xXafdBfO/aYSZ32sj6OQ1RfpvtRzpxryNNvmFQuAZW3zK7u/3oDrZHaf5xt5r8t0M7B9e4e8XewbFM7tzmtkadn60fj5lk8l232XFWLi3x3eZS7LVNtldoZFv7Xsij5X8LnlNdnnmNpIasoZR8zyU8xz6+omq9kgY8vtbkNPdM8g4TAABABBMmAACACCZMAAAAEUyYAAAAIlpk03erLl1MnnNTucm/3OsvwXN+8PIJJm/3y9UmV82eZ/KKBozjK2d/z+SHL/uNyddv83zwnB3Kw0Xo0HK0HtDf5B3vafwGzadceanJPR7iFweyUTV/ocnrD7SPH3Ox/f9bkp64wP4/vlWiCTzp6I6fhccGxTf2LoaTOn9k8q9OHmjy1r+j6bupjLv2ApNHnvqmyeP7PxM854A3Tjb5w4/DTZprG3h72PS9/rLVJj8TWUDzyFfGBdfYZvqbwbG04h0mAACACCZMAAAAEUyYAAAAIlpED1PrfnZxv1F/W2Ty5C3twm4HvXlScI2hp71mcj42V93qFrvJ4JFb296SN8+8KXqNhVfZxeGGXmN7WqpW2b4ClLY1f2hj8k+3mp7x/N9+tGNwrMcf6VkqhD6/DTcR/dLyS0ze7rxZJl/d1y5e297ZDW0lqYNrm4fRWRu9XYj3qLdtf8uUHR5u9DWrw6GjifS+0dbaBzfax4/RbsFzuurdRM6s8uDwGr8dZnuWYgtXbvOltyN3STfeYQIAAIhgwgQAABDBhAkAACCiRfQwzbnIrl3zyJaTTT5x/tEmdzt9XXCNyuBI/g25ZYHJfxvTLThnx752LZMr9/6ryVdcf0Lex4XiWPCbcJPVt3dK9rXZv/NcunxPk+cds2UdV15exzEUQrd7XjL5g8ReyafKbri98cjdg2u8Nzr/zUHbPGe3PP2kPHGPHRp/zb+fb9ec+vqsi4Jz2v09cw8e0mPxt8LO3ZHt7DpL1YnXo+EPnmNyuWz9lxreYQIAAIhgwgQAABDBhAkAACCi2fUwlfXeKjj24JevN3nKerviROXJ9nPYqhUr8z+wBqhcbneg+6iyc3DOfUP+kThi1+WZe+EgkwdfRr9KqWi1y/Ymv31quA5Xcm+m2ZtsnnfC1iZXLluSp9GhGOrq8Sn/e9Pft9Xxe5i8qPLz4JyBrTPvg9cnsU/eg+OvC845tf++wTGkxB47mTjnwAnBKcmepb99bvtut7v6fZML0QvclHiHCQAAIIIJEwAAQAQTJgAAgAgmTAAAABHNrul77b6DgmM7tLXf5kVvjza57YrFTTqmbN2+KGyI/MbO92d8TmWPUm+raznKdhhu8pn3PxZ9zsdVG03+v5/aDZt7vM/Gushdh0dfNnn6b/oH5wzs3LiNvU+d+9U6jvJLCWm12x9eN7laPjgn+Usov/jVaSb3WNK8Xo94hwkAACCCCRMAAEBEdMLknOvvnJvqnHvbOTfLOXdBzfEezrknnXPzav7dvemHi1JFHSFX1BDygTpCthrSw1Qp6WLv/avOuS6SXnHOPSnpdElTvPdXOecul3S5pMuabqgNs+TocIPApG9t+2+T7xppe5r8a7PyOqZsLV9ax/+vO2d+zojr15pcXc95RVBSddQUynr1MrnHbXah0mM6JXtCwr/P7POE3cB02B+bV49ARIuvoWK541snBMeW3zrV5PO2WBCcU9vjIyYHx47SrjmNK0vUUR0+HbOXycd1u9nkVnLBc8a9f7DJPSY079ej6DtM3vtl3vtXa75eK2m2pL6Sjpd0Z81pd0o6oYnGiGaAOkKuqCHkA3WEbDWqh8k5N1DSSEnTJPX23i+reWi5pN75HRqaK+oIuaKGkA/UERqjwRMm51xnSQ9JutB7/2ntx7z3Xqrjdw43P2+cc26Gc25GhTbWdQpakGzqiBpCbbwWIR+oIzRWg9Zhcs610ebCusd7/3DN4RXOuT7e+2XOuT6S6tyx1ns/XtJ4SerqetRZgPnUbWbb8KBtUdLJnRNDvdduaPvb604OLtHr9/n/bLbVziNM/uI9r5j8UPdw89XkZrs7PX+6yYOXvJePoTWJbOuo0DXUVD49YLDJfxlQ18/3fw556yvBse0unWtyvGOveSml16LmpNVzrwXHbr/rKJPPOy9zPacJdRT61zW2Zym5xtL0jeH7K+9fUW5ymV7N/8BSpCG/Jeck3SFptvf+2loPTZY0tubrsZIezf/w0FxQR8gVNYR8oI6QrYa8w7SvpNMkvemcm1lz7PuSrpJ0v3PuTEmLJYVvywD/Qx0hV9QQ8oE6QlaiEybv/b+lOn6fcLND8jscNFfUEXJFDSEfqCNkq9ntJdf75mnBsZEdzzN52NHzTJ69YmuTp//gd8E1vrDvWSa3nd+h0WPbOHiDyU8eeIPJ27a217x5te1xkqS5n9uxDj77A5OrVq9p9LiQf1UHhevLPPC735rcSvbnPWuT3Qew/U+7hdddvTAPowNy1+Odxu1bubTq8yYaCbKx7JHtTG7z3zfbNqtIdGeNefrbwTWGTZ2R72GlGlujAAAARDBhAgAAiGDCBAAAEMGECQAAIKLZNX2rOlzKr+/VthH88+vstz24l13sctdrxgXXeOeg2+2Bg7IcXy1//HSYyb+aeozJ218TrptW/cFymzckN2xFMSQ31u30k/eDc3qUtTM5uTDcOd873+TOz4e/wACkRefZH5u8/R/PyXh+32c2Bcfa6JU6zkTe7bFTcOixXX9vcoVP/tLREJO3v3KZkhrX9l/6eIcJAAAgggkTAABABBMmAACAiObXw1SXRF+T32hz5ZKlJg8aYxeDlKTjR5xi8pxv98x9XD3tTtfDzn7Zjiv3O6BAZv98oMnvDLklOKfK25Xgdnw0saDqI3aD02azqyeapao5800e+MP59ZyJYlt8dJfgWJ8y27PUxpWZ/Ni5B5tctqR5b6zbELzDBAAAEMGECQAAIIIJEwAAQETL6GFqLB92j1TNthv2Dr1wXnAOWi7XIVz/K2nGJrveV/k5dp0lepYANIUes6uDY8l14PZ94ySTu71ie9Lir3DNH+8wAQAARDBhAgAAiGDCBAAAEEEPE5AHW7xg94l7ap9w3ZM7l++bOMI+gACaXpd7XwqOHXfv7iZ31gKT6VkK8Q4TAABABBMmAACACCZMAAAAEUyYAAAAImj6BvKg160vmnzDrSPqOIsmbwAoVbzDBAAAEMGECQAAIIIJEwAAQITzdWw022Q3c+5DSYslbSlpVcFunD3G2TADvPe9CnGjWjUkFf/7bijG2TDFqKNif88NxTgbpmA1JFFHTajY46yzjgo6YfrvTZ2b4b0fVfAbNxLjTLdS+b4ZZ3qVyvfMONOtVL5vxpkbPpIDAACIYMIEAAAQUawJ0/gi3bexGGe6lcr3zTjTq1S+Z8aZbqXyfTPOHBSlhwkAAKCU8JEcAABABBMmAACAiIJOmJxzo51zc5xz851zlxfy3jHOuQnOuZXOubdqHevhnHvSOTev5t/diznGmjH1d85Ndc697Zyb5Zy7IK1jbSrUUc5jbPE1JKW3jkqhhmrG1OLrKK01JJVGHZVaDRVswuScK5N0s6QjJW0vaYxzbvtC3b8BJkoanTh2uaQp3vtySVNqcrFVSrrYe7+9pL0knVPz3zGNY8076igvWnQNSamvo4lKfw1JLbyOUl5DUmnUUWnVkPe+IP9I2lvSE7XyFZKuKNT9GzjGgZLeqpXnSOpT83UfSXOKPcY6xvyopMNKYax5+n6po/yPt0XVUM33l+o6KrUaqhlXi6qjtNdQzZhKqo7SXkOF/Eiur6T3a+UlNcfSrLf3flnN18sl9S7mYJKccwMljZQ0TSkfax5RR3nUQmtIKr06SvXPpoXWUanVkJTin00p1BBN3w3kN091U7MGg3Ous6SHJF3ovf+09mNpGyv+J00/G2qoNKXtZ0MdlaY0/WxKpYYKOWFaKql/rdyv5liarXDO9ZGkmn+vLPJ4JEnOuTbaXFz3eO8frjmcyrE2AeooD1p4DUmlV0ep/Nm08DoqtRqSUvizKaUaKuSEabqkcufcIOdcW0mnSJpcwPtnY7KksTVfj9Xmz1eLyjnnJN0habb3/tpaD6VurE2EOsoRNSSp9OoodT8b6qjkakhK2c+m5GqowA1dR0maK+ldST8odgNXYmyTJC2TVKHNn0WfKamnNnfoz5P0lKQeKRjnftr89uQbkmbW/HNUGsdKHaWzjqihdNdRKdQQdZTuGiqVOiq1GmJrFAAAgAiavgEAACKYMAEAAEQwYQIAAIhgwgQAABDBhAkAACCCCRMAAEBEThMm59xo59wc59x851w6dhNGyaGOkCtqCPlAHSGTrNdhcs6VafOCXYdp86JY0yWN8d6/Xd9z2rp2vr06ZXU/pNcGrdMmv9Fl89zG1hE11Hyt1ServPe9Gvs8XovwH4V8LZKoo+aqvjpqncM195A033u/QJKcc/dKOl5SvcXVXp20pzskh1sijab5Kbk8vVF1RA01X0/5Bxdn+VReiyCpsK9FEnXUXNVXR7l8JNdX0vu18pKaY4ZzbpxzboZzbkaFNuZwOzRT0TqihhDBaxHygTpCRk3e9O29H++9H+W9H9VG7Zr6dmiGqCHkA3WEfKCOWq5cJkxLJfWvlfvVHAMagzpCrqgh5AN1hIxymTBNl1TunBvknGsr6RRJk/MzLLQg1BFyRQ0hH6gjZJR107f3vtI5d66kJySVSZrgvZ+Vt5GhRaCOkCtqCPlAHSEml9+Sk/f+cUmP52ksaKGoI+SKGkI+UEfIhJW+AQAAIpgwAQAARDBhAgAAiGDCBAAAEJFT0zcAoLA++r+9TR75rTdMvq3/8ya/tKEquMa3bzwv4z22mbra5OqZ9e4OArQYvMMEAAAQwYQJAAAgggkTAABABD1MQEqVde0aHHv/Ozua3CqxWXqrRLvKxi9+2uj7dnu4s8ld//xSo6+BpnPJJfeafFynFSZX+DKTd24b9jC9ePF1Ge8x/lvDTL5hyhHBOcOveMvk6nXrMl4TaAjX2k5LXNu2Jm/aa7vgOUsOsudUbFFtcps19r2hgT98Maux8Q4TAABABBMmAACACCZMAAAAEfQwAU2g9cBtg2MbB25p8spd29vH9/zM5FtG3RNc44D2U/Mwusw27lVh8jGrwzV72j0+vcnHgeIZ122uyeec+G5wzk5bn27yVn/uYHKHR17O+7iQcq1s/9y8CbuY7CvqeI+mwpk4Zm/bM/mzrWwdVeu54BJ3rLGvt79+9miT+7xYWedwG4t3mAAAACKYMAEAAEQwYQIAAIhokT1Mu7xm88+3eiXna66oWm/ywXdfGpxTfsMCkyuXrwjOQWlo1amTye+d/wWTf3vmHcFzDunweeZryn6WXy2f5ehy0861Mbny/I/Ccx4v1GiQ9KcP7F5yx5U/kvH8X67aLTg2f10vk6/pP9nkHq3sujZ1eXUfW+Mj/bdMHvyk/X+EdZqav5Vn72nyvMNuMnlpVfga+Phnw02+7d19Tf77bfuZvNWrttdTkvSS3U9xmJqmf453mAAAACKYMAEAAEQwYQIAAIhgwgQAABDRIpu+u5RtMPmXq3Zq9DXO7zHD5N5ldtG2N8feEDznpH2PNbnywEbfFinhtx9s8q/OmGhyrMG7IW5dPTg49siyL9RxZv2qvQuOXTTwSZOP7Lg24zWGb7EyOLakUaNAPrkzbFP+eZMONvnW/s+a/MiCnYNr9P3yLJMP+o39JZXXv3Z9o8f12r63m7zTL843eeiFbOLc3JQNHWTyBec+aPJ+l55tcreHEr9xJclvtDuIb6m5iTOSuXh4hwkAACCCCRMAAEAEEyYAAICIFtnD9NzO7eMnRUw54UKT3x9tH3/n2JtzvgfSa/3Wtmct1gckSZPW9jb5V/eebPLgP9iFTas/Cxf6a732vYYOUZJUcfio4NiRf4yPtbYXlwwMjvXXW426BvKncuFik5fsZR8/9JizTF5/it1MWZKqDxxp8uDvvWjyl763h8kDX7b1Lkk39f13xnFeeNjfTX58l32Dc6pnvp3xGkiP1n23CY5tc4/tb/z9L040eYs/27oqzlK8+cM7TAAAABFMmAAAACKYMAEAAES0yB6mfOjwiN3cr+NpOxRpJCiGTs/NMXnY375j8pBJVcFz2i2ym9huu/AFkyuzGEer9rYfb9Fd5SY/ued1dTwr7EepbfK67iYP/MGG4Jzwu0NatH/MvjYNm9opOMcN6Gty7Of50qSRwbGKi5+t48z/ObPbPJNvP/Do4JytZ0ZujKJJbjC+zcNrgnOee8Ku8TXgrheDc5oT3mECAACIYMIEAAAQwYQJAAAgItrD5JybIOkYSSu99zvWHOsh6T5JAyUtknSy9/6Tphtm+lQcupvJM/cab3J1Hc95a+ZAk8u1PM+jSq/mVkdVq+3n+cPGTY8+p7E9SmU9ewTH5l4+3OTjD55m8uStJyaekblfSZKOn2v3OKy+1N7Xz0nHmkvNrYYKpXpduJ6X3k7P/lyFRh3VzbW204H5/8/2J63+ONxTcvCN803+9MQ9Te76zmqTq2bZ3s9S05B3mCZKSizLqMslTfHel0uaUpOBTCaKOkJuJooaQu4mijpCFqITJu/9vyR9nDh8vKQ7a76+U9IJ+R0WmhvqCLmihpAP1BGyle2yAr2998tqvl4uqXd9JzrnxkkaJ0nt1THL26GZalAdUUPIgNci5AN1hKicm769914Ztojx3o/33o/y3o9qo3a53g7NVKY6oobQELwWIR+oI9Qn23eYVjjn+njvlznn+kgKu8FKWNUXdw2Otf7RCpOfGG6bvNu4MpOv/dguIChJw694w+S6GsNbmGZdR0llw4aY/PmQRFP3RR+aOGnE3cE1tiyLN3HH/HCl/YWFqiu2tCfMsHWaci2qhtBkWnwdrT/S/rn3zml2A/nyp74VPOeS5580+YROT5g8dLJd0HeY3Re65GT7DtNkSWNrvh4r6dH8DActDHWEXFFDyAfqCFHRCZNzbpKkFyUNd84tcc6dKekqSYc55+ZJOrQmA/WijpAragj5QB0hW9GP5Lz3Y+p56JA8jwXNGHWEXFFDyAfqCNli8906dP7J0uDYfUMfMznZf1SRaBE8p3u4QNetd+xv8pBxC+w1165t+CBRVMlF3taPtp//f3CA7WmTpCuPv9/kkzvbNolWciZXN2DRyWyc2eN5m/vYxeb4vR/kw62rR5i8zTPhOpD0cRZP8jWs+yWLM57/wAG3Bse+8eo3Tf7e4i4mD/1C+GdpKWNrFAAAgAgmTAAAABFMmAAAACLoYarDZ1f2DY7teMT5Jm/1qm1aWrafzbccNTG4xpsH3G7yTuPtuhZDzpxncvXnn0fHiuLYdPAuJj/1h98XZyBZGNS6vcm3/u46k8/yF5jc4ZGXm3pISLn1e34WHEuuPZc0Y80Ak6tfn53XMSE3G44YafLfhv7B5As+2Nvk+d8ZGlyj3yuzTPZ7f8HkQw57x+Sn1anR40wT3mECAACIYMIEAAAQwYQJAAAggh6mOpRNfTU4Nnhq5ueU2yV2dP7nZwTnvHnaDTYnepoOHX2uyR0fnpb5piiaRV+3K8gk11DKRpmzf385e8newTlPzbFr23R+xa7VtHaXjSZPOej64BrbtrYrLY1oYzcQXbaX7U0Z/Ejd40Xz1bqf7eOctf8fg3MqfJXJsyvs4+9dO8zkTuL1LE2W7WP/+N/pFvvnz7bXvGKy32j7leqysad9LXnuo2Tf07KGDzCFeIcJAAAgggkTAABABBMmAACACCZMAAAAETR9N5HBPw4bx0dscY7J7xx7s8n9L55r8kcP539cyI8B99i/a4wZfJjJB/ewC7ZJ0sRFtol70+ReJm/9tN2Mt3pBuBnm0MrXMo5r60Qe8/VLgnOe+/XNwbHadt/fjv2jjGejOSjbYbjJo/78VqOv8dWH7eK+Qx56KacxoWkN/MGLGR/3GR+t25Kv2s5/v7iPyeU0fQMAADRvTJgAAAAimDABAABE0MPURPzGjcGxPlPt/LTVsTbfOfApk4/RbvkfGPKi7RMzTF7zhH38L7L9SZLUTfMTR2yuUv51XFnZ6OecvNV0k3+vcNNNlLZkz9JB99l6PmeL5Ea54Ua7q6o3mdzpPf7+3RTef3DH4Jh7pavJAyctMbmib4/oddf3totMLjnGvgIN7P+hyb8aEjbV/mWN/TNq8lbjTT7ou+dFx1FKqHAAAIAIJkwAAAARTJgAAAAi6GEqompVx08CclC2vvGdUd994lSTy9k0NW8+uHQfk6v2/NRk7+0mzl3+1jm4RveJmdfPSVp4VbiJ85gj/2Vy2LMUd8ifLzV58PUvNPoaiPv6sOnBscv2tj+vlWd9bvJWZXaD7Wz8dNVOJp/2wLnBOWWDPjN5dYXdDLzLA+HYSxnvMAEAAEQwYQIAAIhgwgQAABBBDxPQjCz7ru2R+dXZE6LPWVK53uS+T+d1SM1Gq122N3nBid1MfuuMmxpwlVdMauPs+kYVPtFzZn+cm/0i8x3Ca75Sz5m1hessZbqmJN11sv1+v73CrrnTcbnt0ew6ib3lsrF4Q7imUpmz73VsWWZ7hyZ+uo3Jf135heAa854YYnK/p20/Utmc902u+nnYc3vv7neY/P2vnmlPqH4zeE4p4x0mAACACCZMAAAAEUyYAAAAIpgwAQAARND0XUCfbJd5fvqF588weYCaV8Ncsbh2dpNJVz7I5IUnxTeqTBp8wCKTP7u+n8kdHnm50ddsiLJedlPflcfZjXEfu/A3JvdJNIPW5ciJ3zN5wMMsQFiXZJP3a9+83uQKn/s9gqbvPGiKa0rSzm3tdV+8+DqT5yb+g1xz3hHBNT7cZ3W+h9XsTJ+wS3Bs4RVPmrxNa/sa9/OXjjZ50CS7IKoktS23ecGXO5n8g+Nmmby2akFwjXP+3/kmd3u5eTf28w4TAABABBMmAACAiOiEyTnX3zk31Tn3tnNulnPugprjPZxzTzrn5tX8u3vTDxelijpCrqgh5AN1hGw1pIepUtLF3vtXnXNdJL3inHtS0umSpnjvr3LOXS7pckmXNd1QS0vrAf2DYxec/GjG5wz+ySaTm6bzoGiKVkefHbOLyVNvuCXna/5w5W4mz3zkg5yv2Xrgtia/95V+wTl3nfM7k3dom/xfON6zNHLaN0we+DPbb5WHVpymUtTXouTClPnoWSqWMxaPNnnGS8Mynr/1DiuDY//c8d6crilJQ1SUnpeS+jOt163hZsvH9LB9h2+cY2tz/uG32SccHr/Prz6yC7P+6qETTR78s9eC53Tb0Lx7lpKi7zB575d571+t+XqtpNmS+ko6XtKdNafdKemEJhojmgHqCLmihpAP1BGy1ajfknPODZQ0UtI0Sb2998tqHlouqXc9zxknaZwktVfHrAeK5qOxdUQNIYnXIuQDdYTGaHDTt3Ous6SHJF3ovf+09mPee6963sn33o/33o/y3o9qo3Z1nYIWJJs6ooZQG69FyAfqCI3VoHeYnHNttLmw7vHeP1xzeIVzro/3fplzro+k8EPuFuy967oEx87s9p7Jq6o2muw+XdekYyq2YtXRhyevj5/USN/vZfsK1r5nO86mbbCbX0pSr9bmNVmDW9vNLts7u1ZKt1bt67hz5v9lkxvpfvVHlwbn9Ltnusm+sjLjNdOkmK9FO91xrsmvnnF9PWcW19hFh5q8+PrhwTndpr5r8pAPM/eilHUP+5+/0ufr9sCHnzTqmsVU6n+m9btqmsnH3HigyZ8euUP0Gh1W2p7Zsmdtj9JAb1/jwq13W56G/Jack3SHpNne+2trPTRZ0tiar8dKytzRjBaNOkKuqCHkA3WEbDXkHaZ9JZ0m6U3n3MyaY9+XdJWk+51zZ0paLOnkJhkhmgvqCLmihpAP1BGyEp0wee//LSlcV32zQ/I7HDRX1BFyRQ0hH6gjZIu95PJk45G7m3zpdn8JzllYucHkr//Y9pd0fz9cbwO5227rFXm/ZkfX1uYy+/hxnWw/R93smkmtEq/h71TYHjdJmldh95L77hOnmjzi5o9N7j47rKkSXj6oqAY9vMbk8SfadYbGdZtbkHHseseFJrezP3Jtfb3dC7BzHWsdNXaNt6pP6qjnuo6hMKrtT7B67VqTO9+f3v6xUsbWKAAAABFMmAAAACKYMAEAAEQwYQIAAIig6TtLZTvYxeCevP1Wk5MN3pI0+q/fNbl8Ik3ehbD+MrvDwc5HnGfyhj524cYOW37e5GOSpHZTu5rcablt5Oz6zurgOVWz5phcLruAXTPbsDlVqme+bfLfd9jCZu1RkHEM0AvxkwDkHe8wAQAARDBhAgAAiGDCBAAAEEEPUwO12nmEySff/3TG84//Y7jpafmV9B4UxUtvmLhtiazpRj8SAKQH7zABAABEMGECAACIYMIEAAAQQQ9TAw25Y6HJY7osNXn/y+zaPgP/8npwjer8DwsAABQA7zABAABEMGECAACIYMIEAAAQQQ9TA83bfaPJx2l3k7vJLu5DvxIAAM0H7zABAABEMGECAACIYMIEAAAQwYQJAAAgggkTAABABBMmAACACCZMAAAAEUyYAAAAIpz3vnA3c+5DSYslbSlpVcFunD3G2TADvPe9CnGjWjUkFf/7bijG2TDFqKNif88NxTgbpmA1JFFHTajY46yzjgo6YfrvTZ2b4b0fVfAbNxLjTLdS+b4ZZ3qVyvfMONOtVL5vxpkbPpIDAACIYMIEAAAQUawJ0/gi3bexGGe6lcr3zTjTq1S+Z8aZbqXyfTPOHBSlhwkAAKCU8JEcAABABBMmAACAiIJOmJxzo51zc5xz851zlxfy3jHOuQnOuZXOubdqHevhnHvSOTev5t/diznGmjH1d85Ndc697Zyb5Zy7IK1jbSrUUc5jbPE1JKW3jkqhhmrG1OLrKK01JJVGHZVaDRVswuScK5N0s6QjJW0vaYxzbvtC3b8BJkoanTh2uaQp3vtySVNqcrFVSrrYe7+9pL0knVPz3zGNY8076igvWnQNSamvo4lKfw1JLbyOUl5DUmnUUWnVkPe+IP9I2lvSE7XyFZKuKNT9GzjGgZLeqpXnSOpT83UfSXOKPcY6xvyopMNKYax5+n6po/yPt0XVUM33l+o6KrUaqhlXi6qjtNdQzZhKqo7SXkOF/Eiur6T3a+UlNcfSrLf3flnN18sl9S7mYJKccwMljZQ0TSkfax5RR3nUQmtIKr06SvXPpoXWUanVkJTin00p1BBN3w3kN091U7MGg3Ous6SHJF3ovf+09mNpGyv+J00/G2qoNKXtZ0MdlaY0/WxKpYYKOWFaKql/rdyv5liarXDO9ZGkmn+vLPJ4JEnOuTbaXFz3eO8frjmcyrE2AeooD1p4DUmlV0ep/Nm08DoqtRqSUvizKaUaKuSEabqkcufcIOdcW0mnSJpcwPtnY7KksTVfj9Xmz1eLyjnnJN0habb3/tpaD6VurE2EOsoRNSSp9OoodT8b6qjkakhK2c+m5GqowA1dR0maK+ldST8odgNXYmyTJC2TVKHNn0WfKamnNnfoz5P0lKQeKRjnftr89uQbkmbW/HNUGsdKHaWzjqihdNdRKdQQdZTuGiqVOiq1GmJrFAAAgAiavgEAACKYMAEAAEQwYQIAAIhgwgQAABDBhAkAACCCCRMAAEBEThMm59xo59wc59x851w6dhNGyaGOkCtqCPlAHSGTrNdhcs6VafOCXYdp86JY0yWN8d6/Xd9z2rp2vr06ZXU/pNcGrdMmv9Fl89zG1hE11Hyt1ServPe9Gvs8XovwH4V8LZKoo+aqvjpqncM195A033u/QJKcc/dKOl5SvcXVXp20pzskh1sijab5Kbk8vVF1RA01X0/5Bxdn+VReiyCpsK9FEnXUXNVXR7l8JNdX0vu18pKaY4ZzbpxzboZzbkaFNuZwOzRT0TqihhDBaxHygTpCRk3e9O29H++9H+W9H9VG7Zr6dmiGqCHkA3WEfKCOWq5cJkxLJfWvlfvVHAMagzpCrqgh5AN1hIxymTBNl1TunBvknGsr6RRJk/MzLLQg1BFyRQ0hH6gjZJR107f3vtI5d66kJySVSZrgvZ+Vt5GhRaCOkCtqCPlAHSEml9+Sk/f+cUmP52ksaKGoI+SKGkI+UEeFV9azh8mnvvC6yTf+7CSTu939UpOPqT6s9A0AABDBhAkAACCCCRMAAEAEEyYAAICInJq+AQCF5drZxRLn/WqkyQfv+6bJS749ILhG9cx6d/sAmkxZ9+7BsdYPtzX5S52WmXzruuz2u20KvMMEAAAQwYQJAAAgggkTAABABD1MAFBCFl++m8nvfPVGk5dUrjf5zK0uDK7RJu+jAkKuje1Pav1IuFnxX4badULHvX+wyR3/Mi3/A8sS7zABAABEMGECAACIYMIEAAAQQQ9TEX369yEmXzLkSZPHDxtcyOEASJs9dgoOPXbGb0yeut6ubXPNaWeY3ObFGfkfF9AASy8aZfLMoTcF57yb6Ln74Fv9Eme8k+9hZY13mAAAACKYMAEAAEQwYQIAAIigh6mIvHcmV8nVcyaAlqDiULvG0s233xics23rDiYfO/2rJvd/8fX8DwxogCXf38fkaWdfmzijrZLOuPi7Jnd6Kz3rLiXxDhMAAEAEEyYAAIAIJkwAAAARTJgAAAAiaPqWNPcPu5v87JG/C84Z/Yfvmdz/Fy/kfRxf6vSxyb88/9TgnN435P++SInEIoVLD+oSfUrfX2euh/XH7xEc6/LKUpMrl9ic1TimrrUHXn4z+hyENl3yicnD2rQPzplVscnkQeetMrky/8MC6vTZyXuZ/MLZvzW5KnH+DrefG1xj4KN2YVWfl5E1Dd5hAgAAiGDCBAAAEMGECQAAIKJF9jCt+vbeJr9zzA0mt1bH4DmDD1tocsUv8j+uVomFKz/bc31wTu/83xYF0rq/3VTy3W9ta/LE0+wihbu3CxcyrU58wt/qfJf5cb0avcb4NQNNHtdtosltXFlwjQpvuxPaXGDPeWmDffzHg+2CjNjsg0vtQn8zd7Kbk5a58O+0X37+LJOHLHst/wPLQtmWPU3+fE+7eXinV98PnlO5bHmTjgn5s+4rewbH/vW7WxJH2plU/uT/2fzjsOcyzT1LSbzDBAAAEMGECQAAIIIJEwAAQESL7GGqSvSGtFbYo5G05gbbb9JRy/I6prrcsufdwbHfaocmvy9yV9f6R/td+ZLJj2z1qMnVqk7k8O8zyXOSf+eJPV7XOeO6Lcr4eEUdTQaxc9hIumEGHG17I5P9ZT9eadfEkqTyM2cnnpN/rTraPs7VJ+wcnDPi/FkmH9/Tbpp6dMd/mnzBB/sG11h8rO3KrFy+olHjRNNxu9k/ay751T3R5wz927dNHvadsIeylPEOEwAAQAQTJgAAgAgmTAAAABHRHibn3ARJx0ha6b3fseZYD0n3SRooaZGkk733n9R3jbT5yreezvj4P9aH6zB1nrvG5Hz0DXT7qb3PQ3/qbvIxHT8MnnPZuXbdlq1uKo295ZpbHZVtP8zkT6+1O3g9u9OtwXPCNZKSfT727y8rqsJ1uG75yP78f7bVzIzXCO/RkHPs43Wvw6SM55QFu0jlrjnU0Kpxdg24J4ZckzjD7h03aWrY9zN0w0vBsVy5kbZf5aOf2/3qnt/l5ug1knWUfI28fpvng+fseJ7dW2zgD5q+h6k51FFTSPYsnf7nx00+tuOnwXPGLDzM5OHnvG6yr87/60AxNeQdpomSRieOXS5pive+XNKUmgxkMlHUEXIzUdQQcjdR1BGyEJ0wee//JenjxOHjJd1Z8/Wdkk7I77DQ3FBHyBU1hHygjpCtbJcV6O29/8/v1S9Xhh07nHPjJI2TpPZ1bDmCFq1BdUQNIQNei5AP1BGicm769t57ZdgOxns/3ns/yns/qk1inxngPzLVETWEhuC1CPlAHaE+2b7DtMI518d7v8w510fSynwOKt/m/24vkx/qcV3ijLYmnff3scE1yt+aFhzLVavPbWPlbu2WmtzOhX972dQl78MoppKqo9p+9Ngkk0e2y33RyZtXDzH5H6fvH1zDT3/T5B2vtE2zFeVho3iuurzYITjWc9aGjM9pu3xt4si8PI7IKKka6vIVu+Btt1a2yXt2RYXJQx7M/N85W9X7jzS596/tApp/HTDF5DXV4ThOeudrJn/w8jYmTxhjG8X3aJfqbVZLqo6aQrLJ+6TOH5l819qtg+es+4b9A8lXfBSc05xk+w7TZEn/mVWMlfRohnOB+lBHyBU1hHygjhAVnTA55yZJelHScOfcEufcmZKuknSYc26epENrMlAv6gi5ooaQD9QRshX9SM57P6aehw7J81jQjFFHyBU1hHygjpCtFrH57h3HjTe5g2tbz5mbDb13Y1MO5798uzYmD2zNb1yUittWHmjyrf2fNTmbBSMfeH9Xk7dYHq6bV5nI216ZzoVLm9dyddlp1alTcOzA3pl7ub7y0jiTBz0/M59D+q/3zrU/occTPUtJyX4lSWp72GKTt05spLvhFPv6Jm0S0mPuH3cz+aTOdqPcR9ZtYfJNvz0xuEbPBS/mfVxpxtYoAAAAEUyYAAAAIpgwAQAARDS7Hqbk5paSNLJd8nPWzIuNHTX+meDYyk1dGzWORx7eLzjW6zXbgdJhRf7XzEFhzL5uR5Orfzs1cUbj12F6eqf7TD7p7mODa1QeGBxCSq06eefg2I+2TG5iW1evW3599K3wNXHO/r83ucrbcQx/9gyTh3xtZvQ+z/7B9opW+WS9N/33irrNv3tkcGzagTeYvLLKrpP1m5+fY3LPP7WsfqW68A4TAABABBMmAACACCZMAAAAEc2uh2nDluHn5J1d4zZIPG+LBTmP42ffmRkcW1b1ucn7P/7dnO+D4uhy70smH7fA9nwsPSi+6d+E71xv8si29u8vfxlq93aSpFtmDTL5sR26R++D4lhz+OfBser693SVJPWcnPtabK6NXWduv7OmB+ck+4u++d4XTR52jl1jqSHraiWvmfxer/14RPCcoXfYvfWS64whO6379TX5hr0mBef0bGX3iBxxl+1ZGtwEPUuudTjl8FWJ6vLp3XOQd5gAAAAimDABAABEMGECAACIYMIEAAAQ0eyavgc8sDw4dvzhR5vct+Nqk6fMs82IfR7KvDmvJK0eXGbyPie/ZvL5Wz0dPGdEG9vQOf/YW6P3QYl4+U0T+74cf8qVk+2Gpmt+Z5sfn9npgeA547aYb/Jje9hm8+Q4UEQL62jgPiDzU9qtzn3b4ve+N8rkv259Yx1n2V+OeeWvdiHWfp/EN3Wee8seiSN289Y11RtMfuLicNXVNgtmRO+Dxltw5gCTR3cIfwFh75lfNXnID+0vB2TTel1xuK29zy5YY/IXtvwgeM6/3xts8qCz7DlVqz7KYiRNg3eYAAAAIpgwAQAARDBhAgAAiGh2PUxV88JFJ6u+aPOixOND9JoaK9mdsOgam88/5NzgOat2sgto3nXhtSbv0CbeO4WmV7b9sPDgEtsbV/Xppznfp2r2PJM7j7aPf+elsOfj1v7PmpxcILMhvVNo3q795h3Rc06cf6TJ/X9jCyfZv1J5yG7BNV499rrEkfYmHfbqmSZv9U/6lQrlpm/8IXpOq0k9TfaV8+o5c7PWfbYOji080/Yf3XXmdSbv0rYBU4x+z5k4ejtbN62eo4cJAACgZDBhAgAAiGDCBAAAENHsepjSovWUV4JjW0+x+aI37WaHfX9uP0P+04B/5X1ciPvRY+FGlV977GyTy8+f1uTjeHbB0OBYdf+pJg8+yvbsbfx1kw4JJaBH2WeJI+HfixdMHmJyn8oVJif7+E69+dHgGp1b2Z7M5zfa+2xz4XqT2Vi36aw/3q6JtWc7uzn4yqrwv363+eHaTLUlN/Ad8eiy4JzJWyc3CG/8lOLXH21nrzDTrjVnt3QuLt5hAgAAiGDCBAAAEMGECQAAIIIepiJK9jm9fp79LLdq2zR9etty7N7OBcfmnHiLyXu/btfZ6nnHi006pv9olfg7zo5d7b5Lr/B3oNQYev27wbFZY2wvyU5t25i8bmv7kmy7hBqmLLGKUiuF9by+V+KcL9jXno43fWjyqV1W1nEne91fnnSqyX7hrNhQkScbu9q9TTs4u6bfQW98I3hOj5feyHjNeVdvafLkrf8anFPm7OtNlW/8n1l/ue5gO661hXktzQavrgAAABFMmAAAACKYMAEAAEQwYQIAAIig6buIyoYOMvkH2ycXAUMx3LJ6UHBs3BZ2MbUrLrvH5AlP7G9y5ZKlOY/jwMHzg2PVqVrGDZlUrQgbpf9v1mkmvzDSLpJ6wDl2QdTX3gs3vW3zVLgobm2n3X6hya+ffWNwzr++drXJC06224nv0c42ha/3FcE1Rt59kcmDX0lvs25L98Vtwo11px+5u8nvHW3fP5l9wE2JZ5QpKdbk/eT6DiZfcvuZwTn973vd5DS/wvEOEwAAQAQTJgAAgIjohMk51985N9U597ZzbpZz7oKa4z2cc0865+bV/Lt70w8XpYo6Qq6oIeQDdYRsNaSHqVLSxd77V51zXSS94px7UtLpkqZ4769yzl0u6XJJlzXdUJuf6u6dTT6x0ycmJxcFK3ElU0e/e3p0cOw7X7YLV57QabXJx02bbPJ2z4af1W81ub3JHVbavpCN37M///H9HwyuUd2y3xQumRqqz1bnbTT52skjTL5q6+kmz7ot7AtK9kGtm2YXGNzxiDnxcZTZnqUty3w9Z26228SLgmODf1iyPUslX0dJPf/6tslTfmyXPL2qdx19b7dn7oWrq2cpaVbFJpO/9JcLTR5xne3l7Lv4heAaae5ZSoq++nrvl3nvX635eq2k2ZL6Sjpe0p01p90p6YQmGiOaAeoIuaKGkA/UEbLVqN+Sc84NlDRS0jRJvb33y2oeWi6pdz3PGSdpnCS1V8e6TkEL09g6ooaQxGsR8oE6QmM0+P1951xnSQ9JutB7/2ntx7z3XlKd7+l678d770d570e1yWpnJDQn2dQRNYTaeC1CPlBHaKwGvcPknGujzYV1j/f+4ZrDK5xzfbz3y5xzfSTVtTsjMih73/4nu3yFXXPl6q1fK+Rwmlyp1NGIH8wOjn2x/CSTn9npAZOT6yPNPvCO4BrVB9pzkhvpJq9RV79S8pwH/rmvyYNVsn0lDVIqNVSfyoWLTX72SzuavOEhuxnvD7d8K7hGcu0mjcx9XK9tsnV12j3nmzzwRy/nfpMUKfU6Sqpavcbka0862eSzvms345WkuQfb16iXbHudJn5o15ab+txOwTWG37Lc5KELXjLZbjVd+hryW3JO0h2SZnvvr6310GRJY2u+Hivp0fwPD80FdYRcUUPIB+oI2WrIO0z7SjpN0pvOuZk1x74v6SpJ9zvnzpS0WNLJdT8dkEQdIXfUEPKBOkJWohMm7/2/Jbl6Hj4kv8NBc0UdIVfUEPKBOkK22EuuiKpWfWTyMx+U28frWjsDTa7q00+DY51/NMDk3b7/dZMf2/U2k7dtbdfYkqSKRAtpq+A1u1Xk8fCcwZc1756l5q5q/kKTXz5+qMl7HXxg8Jw1h6/LeM1n97Frhn197teCc1b9rZ/JfZ9YZfLAt6mrUuZfm2Xy0NPCc47SrpGr2DobopeCM5pbj1JMi14FDwAAoCGYMAEAAEQwYQIAAIhgwgQAABBB03cx7WI33vz3yD+aXObsInYoopffNLHPCfbhE8+41OQXfnZTcInkopPJv68kH39lY/j3mW/eeZ7J2yrczBKlq3LReyb3mPBecE6PCZmvcbr2M7m1wmtsnThW1cDxAS0Z7zABAABEMGECAACIYMIEAAAQQQ9TEfkZdmPN3X97gcmvXRz2wSCdekywC/0dM2G3es7MDT1LAFAcvMMEAAAQwYQJAAAgggkTAABABD1MKdLnWtufctS14eaI/ehhAQCg4HiHCQAAIIIJEwAAQAQTJgAAgAgmTAAAABFMmAAAACKYMAEAAEQwYQIAAIhgwgQAABDBhAkAACCCCRMAAEAEEyYAAIAIJkwAAAARzntfuJs596GkxZK2lLSqYDfOHuNsmAHe+16FuFGtGpKK/303FONsmGLUUbG/54ZinA1TsBqSqKMmVOxx1llHBZ0w/femzs3w3o8q+I0biXGmW6l834wzvUrle2ac6VYq3zfjzA0fyQEAAEQwYQIAAIgo1oRpfJHu21iMM91K5ftmnOlVKt8z40y3Uvm+GWcOitLDBAAAUEr4SA4AACCCCRMAAEBEQSdMzrnRzrk5zrn5zrnLC3nvGOfcBOfcSufcW7WO9XDOPemcm1fz7+7FHGPNmPo756Y65952zs1yzl2Q1rE2Feoo5zG2+BqS0ltHpVBDNWNq8XWU1hqSSqOOSq2GCjZhcs6VSbpZ0pGStpc0xjm3faHu3wATJY1OHLtc0hTvfbmkKTW52ColXey9317SXpLOqfnvmMax5h11lBctuoak1NfRRKW/hqQWXkcpryGpNOqotGrIe1+QfyTtLemJWvkKSVcU6v4NHONASW/VynMk9an5uo+kOcUeYx1jflTSYaUw1jx9v9RR/sfbomqo5vtLdR2VWg3VjKtF1VHaa6hmTCVVR2mvoUJ+JNdX0vu18pKaY2nW23u/rObr5ZJ6F3MwSc65gZJGSpqmlI81j6ijPGqhNSSVXh2l+mfTQuuo1GpISvHPphRqiKbvBvKbp7qpWYPBOddZ0kOSLvTef1r7sbSNFf+Tpp8NNVSa0vazoY5KU5p+NqVSQ4WcMC2V1L9W7ldzLM1WOOf6SFLNv1cWeTySJOdcG20urnu89w/XHE7lWJsAdZQHLbyGpNKro1T+bFp4HZVaDUkp/NmUUg0VcsI0XVK5c26Qc66tpFMkTS7g/bMxWdLYmq/HavPnq0XlnHOS7pA023t/ba2HUjfWJkId5YgaklR6dZS6nw11VHI1JKXsZ1NyNVTghq6jJM2V9K6kHxS7gSsxtkmSlkmq0ObPos+U1FObO/TnSXpKUo8UjHM/bX578g1JM2v+OSqNY6WO0llH1FC666gUaog6SncNlUodlVoNsTUKAABABE3fAAAAEUyYAAAAIpgwAQAARDBhAgAAiGDCBAAAEMGECQAAIIIJEwAAQMT/B30ZnO5x5qaHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "_, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(16):\n",
    "    axs[i // 4][i % 4].imshow(train[100 * i + i][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:29.054442Z",
     "start_time": "2022-01-13T16:50:29.050742Z"
    },
    "id": "4zNLPpljoCUA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:50:30.618749Z",
     "start_time": "2022-01-13T16:50:30.614821Z"
    },
    "id": "qhSi2aedoCUA"
   },
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import numpy as np\n",
    "from catalyst.utils import get_loader\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "def transform(x: np.array) -> tp.Dict[str, torch.Tensor]:\n",
    "    image = torch.FloatTensor(x[\"image\"])\n",
    "    image = torch.where(image > 127, torch.ones(image.shape), torch.zeros(image.shape))\n",
    "    return {\"image\": image, \"targets\": x[\"targets\"]}\n",
    "\n",
    "\n",
    "train_data_loader = get_loader(\n",
    "    train,\n",
    "    open_fn=lambda x: {\"image\": x[0].reshape(1, 28, 28), \"targets\": x[1]},\n",
    "    dict_transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    sampler=None,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_data_loader = get_loader(\n",
    "    valid,\n",
    "    open_fn=lambda x: {\"image\": x[0].reshape(1, 28, 28), \"targets\": x[1]},\n",
    "    dict_transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwaRij52oCUB"
   },
   "source": [
    "## GAN\n",
    "\n",
    "For GAN model, we need a Discriminator and a Generator. The Discriminator will judge generated images, how do they like real one. The Generator tries to fool the Discriminator.\n",
    "\n",
    "Notice that Generator is similar to Decoder in AE/VAE perspective. It will required later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T16:51:56.383738Z",
     "start_time": "2022-01-13T16:51:56.377802Z"
    },
    "id": "QppAiFFRoCUB"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.clf = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(images)\n",
    "        return self.clf(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:08:51.376276Z",
     "start_time": "2022-01-13T17:08:51.370736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125325663996571831810755483238273420616498507508098617146349500752097059631738116432448839054351520763198615919551594076685828989467263022761790838270854579830015111246661203984624358929832571615718014704096305668097507613273663023226895250541385927158426088684494082416768617708189592286936039922311125683719215046689156738352590137241554510185855964549927575493247391132548534378497978806084951085874202011836362315727420109554782988791530088289711844550500230485638413189947132142243947334199259300735622492937419453650061490302105127920314430401636855677549136337481321811349678427076091437345045399337348611261168055929355402992823192491190360027036112283180935872775214517464013178274657100736321564606838252739601156414628445543663144696050650160812621814327062666195172701780200286645023823083185928061371310300829284071141207731280600001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_numb = 7 ** 1000\n",
    "big_numb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:11:08.671510Z",
     "start_time": "2022-01-13T17:11:08.654152Z"
    },
    "id": "C1cAWstQoCUB"
   },
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn.modules import Lambda\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size: tp.Tuple[int, int] = (28, 28),\n",
    "        latent_size: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.map_generator = nn.Sequential(\n",
    "            nn.Linear(latent_size, 64 * 49),\n",
    "            Lambda(lambda x: x.view(x.size(0), 64, 7, 7)),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            self.make_up_layer_(64, 16),  # 7 -> 14\n",
    "            self.make_up_layer_(16, 4),  # 14 -> 28\n",
    "        )\n",
    "\n",
    "        self.output = nn.Sequential(nn.Conv2d(4, 1, 3, padding=1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, points: torch.Tensor) -> torch.Tensor:\n",
    "        feature_map = self.map_generator(points)\n",
    "        feature_map = self.deconv(feature_map)\n",
    "        return self.output(feature_map)\n",
    "\n",
    "    def make_up_layer_(self, in_channels: int, out_channels: int) -> nn.Module:\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbHTsVWnoCUC"
   },
   "source": [
    "To monitor decoded images, we have to write a new callback function. It will log image into the tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:11:54.993621Z",
     "start_time": "2022-01-13T17:11:54.987704Z"
    },
    "id": "sBPP_oM5oCUC"
   },
   "outputs": [],
   "source": [
    "from catalyst import dl\n",
    "from catalyst.core import Callback, CallbackOrder\n",
    "\n",
    "\n",
    "class LogFigureCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(CallbackOrder.External)\n",
    "\n",
    "    def on_epoch_end(self, runner):\n",
    "        logger = runner.loggers[\"_tensorboard\"]\n",
    "        logger = logger.loggers[runner.loader_key]\n",
    "        logger.add_images(\n",
    "            f\"image/epoch\",\n",
    "            runner.output[\"generated_images\"][:64],\n",
    "            global_step=runner.global_epoch_step,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewegvr2BoCUC"
   },
   "source": [
    "Create model, criterion, optimizer. Train model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:13:32.413415Z",
     "start_time": "2022-01-13T17:13:32.405985Z"
    },
    "id": "E8LnTH0koCUD"
   },
   "outputs": [],
   "source": [
    "from catalyst.contrib.nn.optimizers import RAdam\n",
    "\n",
    "\n",
    "generator_1 = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "model = {\"generator\": generator_1, \"discriminator\": discriminator}  # set models\n",
    "optimizer = {\n",
    "    \"generator\": RAdam(generator_1.parameters(), lr=3e-3, betas=(0.5, 0.999)),\n",
    "    \"discriminator\": RAdam(discriminator.parameters(), lr=3e-3, betas=(0.5, 0.999)),\n",
    "}  # set optimizers\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loaders = {\n",
    "    \"train\": train_data_loader,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:13:34.968631Z",
     "start_time": "2022-01-13T17:13:34.963306Z"
    },
    "id": "vt7Yj5eSoCUD"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    dl.OptimizerCallback(\n",
    "        optimizer_key=\"generator\", metric_key=\"loss_generator\", model_key=\"generator\"\n",
    "    ),\n",
    "    dl.OptimizerCallback(\n",
    "        optimizer_key=\"discriminator\", metric_key=\"loss_discriminator\", model_key=\"discriminator\"\n",
    "    ),\n",
    "    LogFigureCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VuQTlbdoCUD"
   },
   "source": [
    "Training process consists in two phases: discriminator and generator parts. The discriminator is differential metrics of 'fakeness'. So, it's trained to discriminate objects by `BinaryCrossEntropyLoss`. Because the discriminator is differential, we can pass knowledge about real images by backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:20:04.433862Z",
     "start_time": "2022-01-13T17:20:04.425741Z"
    },
    "id": "dS0vYz05oCUD"
   },
   "outputs": [],
   "source": [
    "class GANRunner(dl.Runner):\n",
    "    def handle_batch(self, batch: tp.Dict[str, torch.Tensor]):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"generator\"].latent_size\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "\n",
    "        # Generate fake images by random points\n",
    "        generated_images = self.model[\"generator\"](random_latent_vectors).detach()\n",
    "        # Combine them with real images\n",
    "        combined_images = torch.cat([generated_images, real_images])\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = torch.cat([torch.ones((batch_size, 1)), torch.zeros((batch_size, 1))]).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        # Train the discriminator\n",
    "        predictions = self.model[\"discriminator\"](combined_images)\n",
    "        batch_metrics[\"loss_discriminator\"] = self.criterion(predictions, labels)\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "        # Assemble labels that say 'all real images'\n",
    "        misleading_labels = torch.zeros((batch_size, 1)).to(self.device)\n",
    "\n",
    "        # Train the generator\n",
    "        generated_images = self.model[\"generator\"](random_latent_vectors)\n",
    "        self.output = {\"generated_images\": generated_images}\n",
    "        predictions = self.model[\"discriminator\"](generated_images)\n",
    "        batch_metrics[\"loss_generator\"] = self.criterion(predictions, misleading_labels)\n",
    "\n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = GANRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:20:32.565387Z",
     "start_time": "2022-01-13T17:20:31.026922Z"
    },
    "id": "zfiDKf3VoCUE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-13T17:20:54.841453Z",
     "start_time": "2022-01-13T17:20:52.744129Z"
    },
    "id": "2GgsFngXoCUE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d96424377549a8aaa8189b552089f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/30 * Epoch (train):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'latent_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-438267d8e8ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m runner.train(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/runners/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, loaders, model, engine, trial, criterion, optimizer, scheduler, callbacks, loggers, seed, hparams, num_epochs, logdir, valid_loader, valid_metric, minimize_valid_metric, verbose, timeit, check, overfit, load_best_on_end, fp16, amp, apex, ddp)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_best_on_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_best_on_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_has_str_intersections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"IRunner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;34m\"\"\"Event handler.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \"\"\"\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0;31m# single-device branch (cpu, gpu, dp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_experiment_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, rank, world_size)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_stage_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage_epoch_step\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage_epoch_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-96554a982d26>\u001b[0m in \u001b[0;36mhandle_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mreal_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlatent_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Sample random points in the latent space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/ml-mipt/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'latent_size'"
     ]
    }
   ],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=30,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACatHF8ioCUE"
   },
   "source": [
    "## VAE-GAN\n",
    "\n",
    "Remember that the Discriminator is a Decoder? Let's add an Encoder in our training rutin:\n",
    "\n",
    "![](https://habrastorage.org/web/7a1/8db/d39/7a18dbd3969048c2b085cc707e539f0c.png)\n",
    "\n",
    "It will make latent space meaningfull.\n",
    "\n",
    "To train all these models, we need new loss function for encoder model. We need to compare results from the Discriminator with the real images. Instead from comparing images in the original sizes, we can compare feature maps from the Discriminator.\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1512.09300.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHcfHPcNoCUE"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size: int = 10):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.latent_space = nn.Linear(64, 2 * latent_size)\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> tp.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        features = self.feature_extractor(images)\n",
    "        latent = self.latent_space(features)\n",
    "        return latent[:, : self.latent_size], latent[:, self.latent_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnbyWCPJoCUF"
   },
   "outputs": [],
   "source": [
    "class Discriminator_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.clf = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> tp.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        features = self.feature_extractor(images)\n",
    "        return self.clf(features), features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA9FQ8EkoCUF"
   },
   "outputs": [],
   "source": [
    "class KLVAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, loc: torch.Tensor, log_scale: torch.Tensor) -> torch.Tensor:\n",
    "        return (-0.5 * torch.sum(log_scale - loc.pow(2) - log_scale.exp(), dim=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFTSUSxToCUF"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "generator_2 = Generator()\n",
    "discriminator = Discriminator_v2()\n",
    "\n",
    "model = {\"generator\": generator_2, \"discriminator\": discriminator, \"encoder\": encoder}  # set models\n",
    "optimizer = {\n",
    "    \"generator\": RAdam(generator_2.parameters(), lr=3e-3, betas=(0.5, 0.999)),\n",
    "    \"discriminator\": RAdam(discriminator.parameters(), lr=3e-3, betas=(0.5, 0.999)),\n",
    "    \"encoder\": RAdam(encoder.parameters(), lr=3e-3, betas=(0.5, 0.999)),\n",
    "}  # set optimizers\n",
    "criterion = {\"bce\": nn.BCEWithLogitsLoss(), \"mse\": nn.MSELoss(), \"vae\": KLVAELoss()}\n",
    "loaders = {\"train\": train_data_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evcNxQuHoCUG"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    LogFigureCallback(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgYPwZ58oCUG"
   },
   "source": [
    "Look the architecture and parameter update rutine:\n",
    "\n",
    "Model Architecture:\n",
    "![image](https://habrastorage.org/web/701/bbb/212/701bbb21273045fc9ed4aab7e0529764.png)\n",
    "\n",
    "Parameter Updates:\n",
    "![image](https://habrastorage.org/getpro/habr/post_images/07a/d0b/dc0/07ad0bdc0524f17cd4ae6c6e1be3c36d.svg)\n",
    "\n",
    "What we need to code?\n",
    "\n",
    "- Encoding training: compact latent space (KL Loss) and object reconstruction\n",
    "- Discriminator training: discriminate real from fake and reconstructed\n",
    "- Generator/decoder training: object reconstruction and fake object generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfbOQXVBoCUG"
   },
   "outputs": [],
   "source": [
    "LOG_SCALE_MAX = 2\n",
    "LOG_SCALE_MIN = -10\n",
    "\n",
    "\n",
    "def normal_sample(loc: torch.Tensor, log_scale: torch.Tensor) -> torch.Tensor:\n",
    "    scale = torch.exp(0.5 * log_scale)\n",
    "    return loc + scale * torch.randn_like(scale)\n",
    "\n",
    "\n",
    "class VAEGANRunner(dl.Runner):\n",
    "    def _zero_grad(self):\n",
    "        for optimizer in self.optimizer.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def handle_batch(self, batch: tp.Dict[str, torch.Tensor]):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"generator\"].latent_size\n",
    "\n",
    "        # encoder-decoder part\n",
    "        latent_loc, latent_log_scale = self.model[\"encoder\"](real_images)\n",
    "        loss_prior = self.criterion[\"vae\"](latent_loc, latent_log_scale)\n",
    "\n",
    "        latent_log_scale = torch.clamp(latent_log_scale, LOG_SCALE_MIN, LOG_SCALE_MAX)\n",
    "        latent_vectors = normal_sample(latent_loc, latent_log_scale)\n",
    "\n",
    "        decoded_images = self.model[\"generator\"](latent_vectors)\n",
    "\n",
    "        _, predictions_decoded = self.model[\"discriminator\"](decoded_images)\n",
    "        _, predictions_real = self.model[\"discriminator\"](real_images)\n",
    "        loss_dislike = self.criterion[\"mse\"](decoded_images, real_images)\n",
    "\n",
    "        # generator part\n",
    "\n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "\n",
    "        generated_images = self.model[\"generator\"](random_latent_vectors)\n",
    "\n",
    "        combined_images = torch.cat([generated_images, decoded_images])\n",
    "        labels = torch.zeros((2 * batch_size, 1)).to(self.device)\n",
    "\n",
    "        self.output = {\"generated_images\": generated_images}\n",
    "        predictions, _ = self.model[\"discriminator\"](combined_images)\n",
    "        loss_generator = self.criterion[\"bce\"](predictions, labels)\n",
    "\n",
    "        # discriminator part\n",
    "\n",
    "        latent_vectors = normal_sample(latent_loc, latent_log_scale)\n",
    "        random_latent_vectors = torch.randn(batch_size, latent_size).to(self.device)\n",
    "\n",
    "        decoded_images = self.model[\"generator\"](latent_vectors)\n",
    "        generated_images = self.model[\"generator\"](random_latent_vectors)\n",
    "\n",
    "        combined_images = torch.cat([generated_images, decoded_images, real_images]).detach()\n",
    "        labels = torch.cat([torch.ones((2 * batch_size, 1)), torch.zeros((batch_size, 1))]).to(\n",
    "            self.device\n",
    "        )\n",
    "        predictions, _ = self.model[\"discriminator\"](combined_images)\n",
    "        loss_discriminator = self.criterion[\"bce\"](predictions, labels)\n",
    "\n",
    "        # closely look at the picture above and sum up losses for all part of VAE-GAN\n",
    "        batch_metrics[\"loss_encoder\"] = loss_prior + loss_dislike\n",
    "        batch_metrics[\"loss_generator\"] = loss_dislike + loss_generator\n",
    "        batch_metrics[\"loss_discriminator\"] = loss_discriminator\n",
    "        if self.is_train_loader:\n",
    "            batch_metrics[\"loss_encoder\"].backward(retain_graph=True)\n",
    "            optimizer[\"encoder\"].step()\n",
    "            self._zero_grad()\n",
    "\n",
    "            batch_metrics[\"loss_generator\"].backward(retain_graph=True)\n",
    "            optimizer[\"generator\"].step()\n",
    "            self._zero_grad()\n",
    "\n",
    "            batch_metrics[\"loss_discriminator\"].backward()\n",
    "            optimizer[\"discriminator\"].step()\n",
    "            self._zero_grad()\n",
    "\n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = VAEGANRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8LB8pYAoCUG"
   },
   "outputs": [],
   "source": [
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNr63bFroCUG"
   },
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=30,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7on_tBploCUH"
   },
   "source": [
    "How to compare models? Usually reseacher just closely look at the pictures. But they can use computer brains and eyes to compare generative models. Let's look at the one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj4XqOvgoCUH"
   },
   "source": [
    "## Inception score\n",
    "\n",
    "Wait, wat? We can create numerical metric for generative models? Yes, we can. The metric called Inception score. To calculate it, we need the image classificator and generated images. Let's do it.\n",
    "\n",
    "\\*Inception score usually calculates for generators, trained on ImageNet/CIFAR. But we have no time to train GAN on these datasets. So, we will work with MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24BjDF_ooCUH"
   },
   "outputs": [],
   "source": [
    "clf_model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RAdam(clf_model.parameters(), lr=0.05)\n",
    "\n",
    "runner = dl.SupervisedRunner(\n",
    "    input_key=\"image\",\n",
    "    output_key=\"logits\",\n",
    "    target_key=\"targets\",\n",
    ")\n",
    "runner.train(\n",
    "    model=clf_model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    callbacks=[dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\")],\n",
    "    loaders={\"train\": train_data_loader, \"valid\": valid_data_loader},\n",
    "    num_epochs=20,\n",
    "    verbose=False,\n",
    "    load_best_on_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql-XzGKsoCUH"
   },
   "source": [
    "Inception Score fomulating by this:\n",
    "\n",
    "![](https://www.oreilly.com/library/view/generative-adversarial-networks/9781789136678/assets/0d33c46a-0a5f-4027-919c-30b910e6d93b.png)\n",
    "\n",
    "where $p(y)$  is probability of class in a dataset, $p(y|x)$  is probability of class of object.\n",
    "\n",
    "[Read more on IS](https://medium.com/octavian-ai/a-simple-explanation-of-the-inception-score-372dff6a8c7a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eYbSw36oCUH"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "\n",
    "def inception_score(model: nn.Module):\n",
    "    p_y = torch.ones(10).to(device) / 10\n",
    "    log_is = 0\n",
    "    num_images = 50000\n",
    "    batch_size = 100\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in trange(num_images // batch_size):\n",
    "            latent_size = model.latent_size\n",
    "            random_latent_points = torch.randn((batch_size, latent_size)).to(device)\n",
    "            generated = model(random_latent_points)\n",
    "            logits = clf_model(generated)\n",
    "            p_y_x = torch.softmax(logits, 1)\n",
    "            log_is += (torch.log(p_y_x) * p_y_x - torch.log(p_y) * p_y_x).sum(1)\n",
    "\n",
    "    log_is /= num_images\n",
    "    return torch.exp(log_is.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqumYMweoCUH"
   },
   "outputs": [],
   "source": [
    "inception_score(generator_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilxhkEV5oCUH"
   },
   "outputs": [],
   "source": [
    "inception_score(generator_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vf3mk7_oCUI"
   },
   "source": [
    "## (Additional) Another point in VAE - GAN: AAE\n",
    "\n",
    "AAE stands for Adversarial Autoencoders. It is like a inverted VAE-GAN. A main model become AE, but we will use Discriminator to compare points in a latent space. Let's code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUoMIwCKoCUI"
   },
   "outputs": [],
   "source": [
    "class Disciriminator_v3(nn.Module):\n",
    "    def __init__(self, latent_size: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_size, 100), nn.Dropout(0.1), nn.ReLU(), nn.Linear(100, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C37kyUopoCUI"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_size: int = 10):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.latent_space = nn.Linear(64, latent_size)\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.feature_extractor(images)\n",
    "        latent = self.latent_space(features)\n",
    "        # Instead of VAE, AAE use simple encoder\n",
    "        # because it can be trained by samples, not distributions.\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUFNvefVoCUI"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_size: tp.Tuple[int, int] = (28, 28), latent_size: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "        self.map_generator = nn.Sequential(\n",
    "            nn.Linear(latent_size, 64 * 49),\n",
    "            Lambda(lambda x: x.view(x.size(0), 64, 7, 7)),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            self.make_up_layer_(64, 16),  # 7 -> 14\n",
    "            self.make_up_layer_(16, 4),  # 14 -> 28\n",
    "        )\n",
    "\n",
    "        self.output = nn.Sequential(nn.Conv2d(4, 1, 3, padding=1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, points: torch.Tensor) -> torch.Tensor:\n",
    "        feature_map = self.map_generator(points)\n",
    "        feature_map = self.deconv(feature_map)\n",
    "        return self.output(feature_map)\n",
    "\n",
    "    def make_up_layer_(self, in_channels: int, out_channels: int) -> nn.Module:\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IA6VwjqUoCUI"
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, image_size: tp.Tuple[int, int] = (28, 28), latent_size: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_size)\n",
    "        self.decoder = Decoder(image_size, latent_size)\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> tp.Dict[str, torch.Tensor]:\n",
    "        latent = self.encoder(images)\n",
    "        x_ = self.decoder(latent)\n",
    "\n",
    "        return {\"decoder_result\": x_, \"latent\": latent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBQltexPoCUI"
   },
   "outputs": [],
   "source": [
    "autoencoder = AE()\n",
    "discriminator = Disciriminator_v3()\n",
    "model = {\"autoencoder\": autoencoder, \"discriminator\": discriminator}\n",
    "optimizer = {\n",
    "    \"autoencoder\": RAdam(autoencoder.parameters(), lr=1e-3),\n",
    "    \"discriminator\": RAdam(discriminator.parameters(), lr=1e-4),\n",
    "}\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Jfa-fxGoCUI"
   },
   "outputs": [],
   "source": [
    "callbacks = [LogFigureCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9p40vppoCUJ"
   },
   "outputs": [],
   "source": [
    "class AAERunner(dl.Runner):\n",
    "    def _zero_grad(self):\n",
    "        for optimizer in self.optimizer.values():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    def handle_batch(self, batch: tp.Dict[str, torch.Tensor]):\n",
    "        real_images = batch[\"image\"]\n",
    "        batch_metrics = {}\n",
    "        latent_size = self.model[\"discriminator\"].latent_size\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        output = self.model[\"autoencoder\"](real_images)\n",
    "        fake_latent = output[\"latent\"]\n",
    "        decoded_images = output[\"decoder_result\"]\n",
    "\n",
    "        self.output = {\"generated_images\": decoded_images}\n",
    "        normal_latent = torch.randn(fake_latent.size()).to(self.device)\n",
    "\n",
    "        loss_ae = self.criterion(\n",
    "            decoded_images.reshape(batch_size, -1), real_images.reshape(batch_size, -1)\n",
    "        )\n",
    "\n",
    "        concat_latent = torch.cat([normal_latent, fake_latent]).detach()\n",
    "        target = torch.cat([torch.ones(batch_size), torch.zeros(batch_size)]).to(self.device)\n",
    "        pred = self.model[\"discriminator\"](concat_latent)\n",
    "        batch_metrics[\"loss_discriminator\"] = self.criterion(pred.reshape(-1), target)\n",
    "\n",
    "        fake_pred = self.model[\"discriminator\"](fake_latent)\n",
    "        fake_target = torch.ones(batch_size).to(self.device)\n",
    "        loss_fake_latent = self.criterion(fake_pred.reshape(-1), fake_target)\n",
    "\n",
    "        batch_metrics[\"loss_autoencoder\"] = loss_ae + loss_fake_latent\n",
    "\n",
    "        if self.is_train_loader:\n",
    "            optimizer[\"discriminator\"].zero_grad()\n",
    "            batch_metrics[\"loss_discriminator\"].backward(retain_graph=True)\n",
    "            optimizer[\"discriminator\"].step()\n",
    "\n",
    "            optimizer[\"autoencoder\"].zero_grad()\n",
    "            batch_metrics[\"loss_autoencoder\"].backward()\n",
    "            optimizer[\"autoencoder\"].step()\n",
    "\n",
    "        self.batch_metrics.update(**batch_metrics)\n",
    "\n",
    "\n",
    "runner = AAERunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uNb7eTqwoCUJ"
   },
   "outputs": [],
   "source": [
    "logdir = Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yryrE53voCUJ"
   },
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    callbacks=callbacks,\n",
    "    num_epochs=1000,\n",
    "    verbose=True,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jl9Oz9M_gRF7"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mDBtBlHnrpWn"
   },
   "source": [
    "**Cridentials**\n",
    "\n",
    "Notebook origin is [Catalyst DL course](https://github.com/catalyst-team/dl-course)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gans",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ml-mipt]",
   "language": "python",
   "name": "conda-env-ml-mipt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
